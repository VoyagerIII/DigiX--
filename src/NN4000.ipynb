{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model,save_model\n",
    "from keras.layers import Dense, Dropout, Activation,LeakyReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from scipy import sparse\n",
    "import gc\n",
    "import printTime as pt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-22 14:57:50\n"
     ]
    }
   ],
   "source": [
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2010000, 4000)\n",
      "(2010000,)\n"
     ]
    }
   ],
   "source": [
    "csr_trainData = sparse.load_npz(r'../trainTestData/trainData4000.npz')\n",
    "print(csr_trainData.shape)\n",
    "\n",
    "age_train = pd.read_csv(r'../data/age_train.csv',header=None)\n",
    "label = age_train[1].values\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-22 14:57:54\n"
     ]
    }
   ],
   "source": [
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "model_filePath = r'../model/NN_model_0_'\n",
    "currK = 0\n",
    "val_index_list, score = [], []\n",
    "val_probability = np.zeros((2010000,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-22 14:57:54\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "0 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 82s 45us/step - loss: 0.9447 - acc: 0.6011 - val_loss: 0.9211 - val_acc: 0.6119\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.9042 - acc: 0.6188 - val_loss: 0.9106 - val_acc: 0.6156\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 73s 41us/step - loss: 0.8834 - acc: 0.6279 - val_loss: 0.9091 - val_acc: 0.6174\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8607 - acc: 0.6387 - val_loss: 0.9191 - val_acc: 0.6110\n",
      "Epoch 00004: early stopping\n",
      "\n",
      " 0 train Done!\n",
      "2019-08-22 15:03:02\n",
      "0 val_acc: 0.6173880597014926 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "1 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 77s 43us/step - loss: 0.9446 - acc: 0.6012 - val_loss: 0.9236 - val_acc: 0.6093\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 75s 42us/step - loss: 0.9049 - acc: 0.6183 - val_loss: 0.9130 - val_acc: 0.6149\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 75s 41us/step - loss: 0.8850 - acc: 0.6275 - val_loss: 0.9128 - val_acc: 0.6149\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8634 - acc: 0.6371 - val_loss: 0.9187 - val_acc: 0.6119\n",
      "Epoch 00004: early stopping\n",
      "\n",
      " 1 train Done!\n",
      "2019-08-22 15:08:16\n",
      "1 val_acc: 0.6149452736318408 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "2 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 78s 43us/step - loss: 0.9448 - acc: 0.6010 - val_loss: 0.9329 - val_acc: 0.6037\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.9041 - acc: 0.6189 - val_loss: 0.9128 - val_acc: 0.6142\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8831 - acc: 0.6284 - val_loss: 0.9152 - val_acc: 0.6142\n",
      "Epoch 00003: early stopping\n",
      "\n",
      " 2 train Done!\n",
      "2019-08-22 15:12:13\n",
      "2 val_acc: 0.6141592039800995 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "3 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 77s 42us/step - loss: 0.9452 - acc: 0.6007 - val_loss: 0.9175 - val_acc: 0.6144\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 75s 41us/step - loss: 0.9043 - acc: 0.6185 - val_loss: 0.9115 - val_acc: 0.6150\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8826 - acc: 0.6283 - val_loss: 0.9175 - val_acc: 0.6107\n",
      "Epoch 00003: early stopping\n",
      "\n",
      " 3 train Done!\n",
      "2019-08-22 15:16:09\n",
      "3 val_acc: 0.6150149253731343 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "4 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 76s 42us/step - loss: 0.9451 - acc: 0.6010 - val_loss: 0.9189 - val_acc: 0.6130\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.9046 - acc: 0.6184 - val_loss: 0.9103 - val_acc: 0.6171\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8836 - acc: 0.6278 - val_loss: 0.9092 - val_acc: 0.6178\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8602 - acc: 0.6385 - val_loss: 0.9128 - val_acc: 0.6170\n",
      "Epoch 00004: early stopping\n",
      "\n",
      " 4 train Done!\n",
      "2019-08-22 15:21:18\n",
      "4 val_acc: 0.6177512437810945 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "5 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 76s 42us/step - loss: 0.9448 - acc: 0.6009 - val_loss: 0.9209 - val_acc: 0.6130\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.9040 - acc: 0.6186 - val_loss: 0.9102 - val_acc: 0.6173\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8833 - acc: 0.6275 - val_loss: 0.9145 - val_acc: 0.6144\n",
      "Epoch 00003: early stopping\n",
      "\n",
      " 5 train Done!\n",
      "2019-08-22 15:25:15\n",
      "5 val_acc: 0.6172935323383084 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "6 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 77s 42us/step - loss: 0.9446 - acc: 0.6010 - val_loss: 0.9207 - val_acc: 0.6122\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 73s 41us/step - loss: 0.9040 - acc: 0.6189 - val_loss: 0.9121 - val_acc: 0.6151\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8829 - acc: 0.6279 - val_loss: 0.9144 - val_acc: 0.6146\n",
      "Epoch 00003: early stopping\n",
      "\n",
      " 6 train Done!\n",
      "2019-08-22 15:29:09\n",
      "6 val_acc: 0.6150845771144279 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "7 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 77s 42us/step - loss: 0.9448 - acc: 0.6016 - val_loss: 0.9272 - val_acc: 0.6080\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.9043 - acc: 0.6191 - val_loss: 0.9142 - val_acc: 0.6135\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8839 - acc: 0.6279 - val_loss: 0.9133 - val_acc: 0.6138\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8620 - acc: 0.6377 - val_loss: 0.9202 - val_acc: 0.6131\n",
      "Epoch 00004: early stopping\n",
      "\n",
      " 7 train Done!\n",
      "2019-08-22 15:34:19\n",
      "7 val_acc: 0.6138308457711443 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "8 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 77s 42us/step - loss: 0.9456 - acc: 0.6008 - val_loss: 0.9267 - val_acc: 0.6074\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.9042 - acc: 0.6185 - val_loss: 0.9156 - val_acc: 0.6114\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8837 - acc: 0.6281 - val_loss: 0.9120 - val_acc: 0.6150\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8614 - acc: 0.6378 - val_loss: 0.9168 - val_acc: 0.6132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: early stopping\n",
      "\n",
      " 8 train Done!\n",
      "2019-08-22 15:39:30\n",
      "8 val_acc: 0.6149701492537314 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "9 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 76s 42us/step - loss: 0.9466 - acc: 0.6006 - val_loss: 0.9149 - val_acc: 0.6134\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.9055 - acc: 0.6180 - val_loss: 0.9066 - val_acc: 0.6181\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8852 - acc: 0.6270 - val_loss: 0.9059 - val_acc: 0.6187\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 74s 41us/step - loss: 0.8634 - acc: 0.6374 - val_loss: 0.9089 - val_acc: 0.6166\n",
      "Epoch 00004: early stopping\n",
      "\n",
      " 9 train Done!\n",
      "2019-08-22 15:44:39\n",
      "9 val_acc: 0.618681592039801 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "mean val_acc: 0.615920895502935\n",
      "2019-08-22 15:44:48\n"
     ]
    }
   ],
   "source": [
    "pt.printTime()\n",
    "for train_index, val_index in kfold.split(csr_trainData,label):\n",
    "    K.clear_session()\n",
    "    trainData, trainLabel, valData, valLabel = csr_trainData[train_index,:], label[train_index], csr_trainData[val_index,:] , label[val_index] \n",
    "    trainLabel,valLabel = np_utils.to_categorical(trainLabel,num_classes=7),np_utils.to_categorical(valLabel,num_classes=7)\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print(currK,'split Done!\\n')\n",
    "    \n",
    "    # 全连接模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4000, activation='tanh', input_shape=(csr_trainData.shape[1],)))\n",
    "    model.add(Dense(2000, activation='relu'))\n",
    "    model.add(Dense(1000, activation='sigmoid'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    #损失函数使用交叉熵\n",
    "    adam = Adam(lr=0.0003)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer = adam,\n",
    "                  metrics=['accuracy'])\n",
    "    #模型训练\n",
    "    batch_size = 1024\n",
    "    epochs = 100\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=1, verbose=2)\n",
    "    bestModel = ModelCheckpoint(model_filePath + str(currK) + r'.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    hist = model.fit(trainData, trainLabel,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      shuffle=True,\n",
    "                      validation_data=(valData,valLabel),\n",
    "                      callbacks=[early_stopping,bestModel],\n",
    "                     ) \n",
    "    print('\\n',currK,'train Done!')\n",
    "    pt.printTime()\n",
    "    \n",
    "    K.clear_session()\n",
    "    model = load_model(model_filePath + str(currK) + r'.h5')\n",
    "    probability = model.predict(valData,batch_size=1024)\n",
    "    val_probability[val_index,:] = probability\n",
    "    \n",
    "    score.append(np.max(hist.history['val_acc']))\n",
    "    y_label = label[val_index]\n",
    "    val_label = np.argmax(probability,axis=1) \n",
    "    print(currK,'val_acc:',accuracy_score(val_label,y_label),'\\n\\n')\n",
    "    \n",
    "    currK += 1\n",
    "    K.clear_session()\n",
    "    del trainData, valData, trainLabel,valLabel,model\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------')\n",
    "print('mean val_acc:', np.mean(score))\n",
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6159119402985075"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(val_probability,axis=1) ,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46154"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del csr_trainData \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2010000, 7)\n",
      "              0         1         2         3         4         5         6\n",
      "0  1.189088e-08  0.002612  0.055671  0.103340  0.246336  0.523377  0.068664\n",
      "1  2.392564e-08  0.560282  0.264407  0.048404  0.088724  0.025450  0.012733\n",
      "2  5.367820e-08  0.004667  0.039767  0.200779  0.342570  0.323843  0.088374\n",
      "3  3.582242e-07  0.057763  0.222979  0.355596  0.232047  0.086177  0.045438\n",
      "4  8.326022e-09  0.092375  0.444669  0.330942  0.100234  0.026543  0.005238\n"
     ]
    }
   ],
   "source": [
    "val_probability = pd.DataFrame(val_probability)\n",
    "print(val_probability.shape)\n",
    "print(val_probability.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probability.drop(labels=[0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probability.to_csv(r'../processed/val_probabilit_0.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = r'../model/NN_model_0_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502500, 4000)\n"
     ]
    }
   ],
   "source": [
    "csr_testData = sparse.load_npz(r'../trainTestData/testData4000.npz')\n",
    "print(csr_testData.shape)\n",
    "\n",
    "age_test = pd.read_csv(r'../data/age_test.csv',header=None,usecols=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-22 15:45:10\n",
      "502500/502500 [==============================] - 11s 22us/step\n",
      "1\n",
      "502500/502500 [==============================] - 11s 22us/step\n",
      "2\n",
      "502500/502500 [==============================] - 11s 22us/step\n",
      "3\n",
      "502500/502500 [==============================] - 11s 22us/step\n",
      "4\n",
      "502500/502500 [==============================] - 11s 22us/step\n",
      "5\n",
      "502500/502500 [==============================] - 11s 22us/step\n",
      "6\n",
      "502500/502500 [==============================] - 11s 22us/step\n",
      "7\n",
      "502500/502500 [==============================] - 11s 22us/step\n",
      "8\n",
      "502500/502500 [==============================] - 11s 22us/step\n",
      "9\n",
      "502500/502500 [==============================] - 11s 22us/step\n",
      "10\n",
      "2019-08-22 15:47:28\n"
     ]
    }
   ],
   "source": [
    "pt.printTime()\n",
    "proflag = True\n",
    "model_Num = 0\n",
    "for i in list(range(10)):\n",
    "    model = load_model(model_file + str(i) + '.h5')\n",
    "    if proflag==True:\n",
    "        probability = model.predict(csr_testData,batch_size=1024,verbose=1)\n",
    "        proflag = False\n",
    "    else:\n",
    "        probability += model.predict(csr_testData,batch_size=1024,verbose=1)\n",
    "    model_Num += 1\n",
    "    print(model_Num)\n",
    "    K.clear_session()\n",
    "    del model\n",
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability /= model_Num\n",
    "age = np.argmax(probability,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_test = pd.read_csv(r'../data/age_test.csv',header=None,usecols=[0])\n",
    "age_test = age_test.values\n",
    "type(age_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502500, 7)\n",
      "(502500, 6)\n"
     ]
    }
   ],
   "source": [
    "print(probability.shape)\n",
    "pro = np.column_stack((age_test,probability))\n",
    "pro = pd.DataFrame(pro)\n",
    "pro.drop(labels=[0,1],axis=1,inplace=True)\n",
    "print(pro.shape)\n",
    "pro.to_csv(r'../processed/test_probability_0.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-22 15:47:33\n"
     ]
    }
   ],
   "source": [
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

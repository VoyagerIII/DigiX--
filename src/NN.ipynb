{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model,save_model\n",
    "from keras.layers import Dense, Dropout, Activation,LeakyReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from scipy import sparse\n",
    "import gc\n",
    "from time import strftime, localtime\n",
    "import printTime as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 16:58:04\n"
     ]
    }
   ],
   "source": [
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_trainData = sparse.load_npz(r'../trainTestData/trainData23100.npz')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 16:58:51\n"
     ]
    }
   ],
   "source": [
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2010000,)\n"
     ]
    }
   ],
   "source": [
    "age_train = pd.read_csv(r'../data/age_train.csv',header=None)\n",
    "label = age_train[1].values\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filePath = r'../model/NN_model23100_NN_'\n",
    "currK = 0\n",
    "val_index_list, score = [], []\n",
    "val_probability = np.zeros((2010000,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 使用指定显卡\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 16:58:52\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "0 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 329s 182us/step - loss: 0.9513 - acc: 0.6028 - val_loss: 0.8836 - val_acc: 0.6286\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 323s 179us/step - loss: 0.8570 - acc: 0.6404 - val_loss: 0.8546 - val_acc: 0.6404\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 324s 179us/step - loss: 0.8287 - acc: 0.6524 - val_loss: 0.8485 - val_acc: 0.6423\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 322s 178us/step - loss: 0.8041 - acc: 0.6637 - val_loss: 0.8466 - val_acc: 0.6428\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 322s 178us/step - loss: 0.7775 - acc: 0.6758 - val_loss: 0.8529 - val_acc: 0.6416\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 0 train Done!\n",
      "2019-08-21 17:26:16\n",
      "0 val_acc: 0.6428258706467662 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "1 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 326s 180us/step - loss: 0.9699 - acc: 0.5958 - val_loss: 0.8843 - val_acc: 0.6286\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 330s 183us/step - loss: 0.8606 - acc: 0.6389 - val_loss: 0.8605 - val_acc: 0.6373\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 324s 179us/step - loss: 0.8339 - acc: 0.6505 - val_loss: 0.8522 - val_acc: 0.6401\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 325s 180us/step - loss: 0.8095 - acc: 0.6611 - val_loss: 0.8519 - val_acc: 0.6404\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 323s 179us/step - loss: 0.7856 - acc: 0.6725 - val_loss: 0.8510 - val_acc: 0.6422\n",
      "Epoch 6/100\n",
      "1809000/1809000 [==============================] - 324s 179us/step - loss: 0.7571 - acc: 0.6867 - val_loss: 0.8617 - val_acc: 0.6382\n",
      "Epoch 00006: early stopping\n",
      "\n",
      " 1 train Done!\n",
      "2019-08-21 17:59:51\n",
      "1 val_acc: 0.6421940298507463 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "2 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 329s 182us/step - loss: 0.9506 - acc: 0.6033 - val_loss: 0.8815 - val_acc: 0.6289\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 325s 179us/step - loss: 0.8562 - acc: 0.6405 - val_loss: 0.8585 - val_acc: 0.6379\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 325s 180us/step - loss: 0.8279 - acc: 0.6528 - val_loss: 0.8503 - val_acc: 0.6419\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 326s 180us/step - loss: 0.8025 - acc: 0.6642 - val_loss: 0.8502 - val_acc: 0.6406\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 328s 181us/step - loss: 0.7758 - acc: 0.6767 - val_loss: 0.8553 - val_acc: 0.6396\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 2 train Done!\n",
      "2019-08-21 18:28:05\n",
      "2 val_acc: 0.6406318407960199 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "3 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 331s 183us/step - loss: 0.9525 - acc: 0.6033 - val_loss: 0.8787 - val_acc: 0.6305\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 340s 188us/step - loss: 0.8581 - acc: 0.6403 - val_loss: 0.8571 - val_acc: 0.6392\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 340s 188us/step - loss: 0.8298 - acc: 0.6521 - val_loss: 0.8489 - val_acc: 0.6419\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 333s 184us/step - loss: 0.8060 - acc: 0.6626 - val_loss: 0.8482 - val_acc: 0.6430\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 339s 187us/step - loss: 0.7798 - acc: 0.6753 - val_loss: 0.8541 - val_acc: 0.6411\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 3 train Done!\n",
      "2019-08-21 18:57:07\n",
      "3 val_acc: 0.6430049751243782 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "4 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 327s 181us/step - loss: 0.9573 - acc: 0.5999 - val_loss: 0.8783 - val_acc: 0.6321\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 328s 181us/step - loss: 0.8585 - acc: 0.6399 - val_loss: 0.8561 - val_acc: 0.6418\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 335s 185us/step - loss: 0.8303 - acc: 0.6514 - val_loss: 0.8468 - val_acc: 0.6451\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 336s 186us/step - loss: 0.8058 - acc: 0.6627 - val_loss: 0.8447 - val_acc: 0.6459\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 334s 184us/step - loss: 0.7801 - acc: 0.6748 - val_loss: 0.8547 - val_acc: 0.6412\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 4 train Done!\n",
      "2019-08-21 19:25:48\n",
      "4 val_acc: 0.6459353233830846 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "5 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 329s 182us/step - loss: 0.9508 - acc: 0.6021 - val_loss: 0.8780 - val_acc: 0.6327\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 333s 184us/step - loss: 0.8578 - acc: 0.6400 - val_loss: 0.8592 - val_acc: 0.6401\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 335s 185us/step - loss: 0.8293 - acc: 0.6521 - val_loss: 0.8473 - val_acc: 0.6445\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 330s 183us/step - loss: 0.8047 - acc: 0.6631 - val_loss: 0.8485 - val_acc: 0.6440\n",
      "Epoch 00004: early stopping\n",
      "\n",
      " 5 train Done!\n",
      "2019-08-21 19:48:55\n",
      "5 val_acc: 0.644497512437811 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "6 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 327s 181us/step - loss: 0.9603 - acc: 0.5987 - val_loss: 0.8839 - val_acc: 0.6288\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 331s 183us/step - loss: 0.8596 - acc: 0.6392 - val_loss: 0.8597 - val_acc: 0.6378\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 327s 181us/step - loss: 0.8305 - acc: 0.6517 - val_loss: 0.8494 - val_acc: 0.6437\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 328s 181us/step - loss: 0.8059 - acc: 0.6625 - val_loss: 0.8495 - val_acc: 0.6424\n",
      "Epoch 00004: early stopping\n",
      "\n",
      " 6 train Done!\n",
      "2019-08-21 20:11:46\n",
      "6 val_acc: 0.6436517412935323 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "7 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 320s 177us/step - loss: 0.9685 - acc: 0.5966 - val_loss: 0.8800 - val_acc: 0.6298\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 325s 180us/step - loss: 0.8591 - acc: 0.6398 - val_loss: 0.8599 - val_acc: 0.6383\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 332s 184us/step - loss: 0.8313 - acc: 0.6513 - val_loss: 0.8553 - val_acc: 0.6393\n",
      "Epoch 4/100\n",
      " 552960/1809000 [========>.....................] - ETA: 3:30 - loss: 0.8027 - acc: 0.6645"
     ]
    }
   ],
   "source": [
    "pt.printTime()\n",
    "for train_index, val_index in kfold.split(csr_trainData,label):\n",
    "    K.clear_session()\n",
    "    trainData, trainLabel, valData, valLabel = csr_trainData[train_index,:], label[train_index], csr_trainData[val_index,:] , label[val_index] \n",
    "    trainLabel,valLabel = np_utils.to_categorical(trainLabel,num_classes=7),np_utils.to_categorical(valLabel,num_classes=7)\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print(currK,'split Done!\\n')\n",
    "    \n",
    "    # 全连接模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3000, activation='tanh', input_shape=(csr_trainData.shape[1],)))\n",
    "    model.add(Dense(2000, activation='relu'))\n",
    "    model.add(Dense(1000, activation='sigmoid'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    #损失函数使用交叉熵\n",
    "    adam = Adam(lr=0.0003)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer = adam,\n",
    "                  metrics=['accuracy'])\n",
    "    #模型训练\n",
    "    batch_size = 10240\n",
    "    epochs = 100\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=1, verbose=2)\n",
    "    bestModel = ModelCheckpoint(model_filePath + str(currK) + r'.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    hist = model.fit(trainData, trainLabel,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      shuffle=True,\n",
    "                      validation_data=(valData,valLabel),\n",
    "                      callbacks=[early_stopping,bestModel],\n",
    "                     ) \n",
    "    print('\\n',currK,'train Done!')\n",
    "    pt.printTime()\n",
    "    \n",
    "    K.clear_session()\n",
    "    model = load_model(model_filePath + str(currK) + r'.h5')\n",
    "    probability = model.predict(valData,batch_size=1024)\n",
    "    val_probability[val_index,:] = probability\n",
    "    \n",
    "    score.append(np.max(hist.history['val_acc']))\n",
    "    y_label = label[val_index]\n",
    "    val_label = np.argmax(probability,axis=1) \n",
    "    print(currK,'val_acc:',accuracy_score(val_label,y_label),'\\n\\n')\n",
    "    \n",
    "    currK += 1\n",
    "    K.clear_session()\n",
    "    del trainData, valData, trainLabel,valLabel,model\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------')\n",
    "print('mean val_acc:', np.mean(score))\n",
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(val_probability,axis=1) ,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del csr_trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2010000, 6)\n",
      "          1         2         3         4         5         6\n",
      "0  0.001006  0.016241  0.064233  0.182788  0.562305  0.173341\n",
      "1  0.401959  0.411980  0.104222  0.061859  0.014824  0.005129\n",
      "2  0.002896  0.061216  0.313714  0.304235  0.271872  0.045998\n",
      "3  0.067550  0.295213  0.464418  0.107411  0.056571  0.008704\n",
      "4  0.069203  0.627658  0.209653  0.058043  0.027779  0.007608\n"
     ]
    }
   ],
   "source": [
    "val_probability = pd.DataFrame(val_probability)\n",
    "print(val_probability.shape)\n",
    "print(val_probability.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probability.drop(labels=[0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probability.to_csv(r'../processed/val_probability_23100.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = r'../model/model23100_NN_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_testData = sparse.load_npz(r'../trainTestData/testData23100.npz')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_test = pd.read_csv(r'../data/age_test.csv',header=None,usecols=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 21:43:07\n",
      "502500/502500 [==============================] - 80s 160us/step\n",
      "1\n",
      "502500/502500 [==============================] - 82s 163us/step\n",
      "2\n",
      "502500/502500 [==============================] - 82s 163us/step\n",
      "3\n",
      "502500/502500 [==============================] - 81s 160us/step\n",
      "4\n",
      "502500/502500 [==============================] - 80s 159us/step\n",
      "5\n",
      "502500/502500 [==============================] - 80s 158us/step\n",
      "6\n",
      "502500/502500 [==============================] - 79s 157us/step\n",
      "7\n",
      "502500/502500 [==============================] - 79s 157us/step\n",
      "8\n",
      "502500/502500 [==============================] - 80s 159us/step\n",
      "9\n",
      "502500/502500 [==============================] - 79s 156us/step\n",
      "10\n",
      "2019-08-21 21:57:42\n"
     ]
    }
   ],
   "source": [
    "pt.printTime()\n",
    "proflag = True\n",
    "model_Num = 0\n",
    "for i in list(range(10)):\n",
    "    model = load_model(model_file + str(i) + '.h5')\n",
    "    if proflag==True:\n",
    "        probability = model.predict(csr_testData,batch_size=1024,verbose=1)\n",
    "        proflag = False\n",
    "    else:\n",
    "        probability += model.predict(csr_testData,batch_size=1024,verbose=1)\n",
    "    model_Num += 1\n",
    "    print(model_Num)\n",
    "    K.clear_session()\n",
    "    del model\n",
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability /= model_Num\n",
    "age = np.argmax(probability,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_test = pd.read_csv(r'../data/age_test.csv',header=None,usecols=[0])\n",
    "age_test = age_test.values\n",
    "type(age_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502500, 7)\n",
      "(502500, 6)\n"
     ]
    }
   ],
   "source": [
    "print(probability.shape)\n",
    "pro = np.column_stack((age_test,probability))\n",
    "pro = pd.DataFrame(pro)\n",
    "pro.drop(labels=[0,1],axis=1,inplace=True)\n",
    "print(pro.shape)\n",
    "pro.to_csv(r'../processed/test_probability_23100.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model,save_model\n",
    "from keras.layers import Dense, Dropout, Activation,LeakyReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from scipy import sparse\n",
    "import gc\n",
    "from time import strftime, localtime\n",
    "import printTime as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 16:56:58\n"
     ]
    }
   ],
   "source": [
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_trainData = sparse.load_npz(r'../trainTestData/trainData13100.npz')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 16:57:40\n"
     ]
    }
   ],
   "source": [
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2010000,)\n"
     ]
    }
   ],
   "source": [
    "age_train = pd.read_csv(r'../data/age_train.csv',header=None)\n",
    "label = age_train[1].values\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filePath = r'../model/model13100_NN_'\n",
    "currK = 0\n",
    "val_index_list, score = [], []\n",
    "val_probability = np.zeros((2010000,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 使用指定显卡\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 16:57:41\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "0 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 214s 118us/step - loss: 0.9556 - acc: 0.6009 - val_loss: 0.8914 - val_acc: 0.6257\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 206s 114us/step - loss: 0.8659 - acc: 0.6363 - val_loss: 0.8624 - val_acc: 0.6369\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 206s 114us/step - loss: 0.8399 - acc: 0.6473 - val_loss: 0.8570 - val_acc: 0.6382\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 207s 114us/step - loss: 0.8176 - acc: 0.6575 - val_loss: 0.8544 - val_acc: 0.6395\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 205s 114us/step - loss: 0.7934 - acc: 0.6688 - val_loss: 0.8592 - val_acc: 0.6376\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 0 train Done!\n",
      "2019-08-21 17:15:20\n",
      "0 val_acc: 0.6394825870646766 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "1 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 207s 115us/step - loss: 0.9734 - acc: 0.5944 - val_loss: 0.8907 - val_acc: 0.6253\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 207s 114us/step - loss: 0.8691 - acc: 0.6350 - val_loss: 0.8677 - val_acc: 0.6348\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 207s 114us/step - loss: 0.8449 - acc: 0.6454 - val_loss: 0.8600 - val_acc: 0.6367\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 209s 116us/step - loss: 0.8229 - acc: 0.6549 - val_loss: 0.8589 - val_acc: 0.6362\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 212s 117us/step - loss: 0.8013 - acc: 0.6656 - val_loss: 0.8564 - val_acc: 0.6383\n",
      "Epoch 6/100\n",
      "1809000/1809000 [==============================] - 213s 118us/step - loss: 0.7756 - acc: 0.6780 - val_loss: 0.8667 - val_acc: 0.6352\n",
      "Epoch 00006: early stopping\n",
      "\n",
      " 1 train Done!\n",
      "2019-08-21 17:36:56\n",
      "1 val_acc: 0.6382636815920398 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "2 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 212s 117us/step - loss: 0.9553 - acc: 0.6013 - val_loss: 0.8887 - val_acc: 0.6257\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 212s 117us/step - loss: 0.8649 - acc: 0.6369 - val_loss: 0.8659 - val_acc: 0.6349\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 212s 117us/step - loss: 0.8392 - acc: 0.6478 - val_loss: 0.8589 - val_acc: 0.6378\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 213s 117us/step - loss: 0.8160 - acc: 0.6581 - val_loss: 0.8580 - val_acc: 0.6374\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 211s 117us/step - loss: 0.7917 - acc: 0.6697 - val_loss: 0.8624 - val_acc: 0.6356\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 2 train Done!\n",
      "2019-08-21 17:55:18\n",
      "2 val_acc: 0.6374179104477612 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "3 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 209s 115us/step - loss: 0.9568 - acc: 0.6013 - val_loss: 0.8849 - val_acc: 0.6274\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 206s 114us/step - loss: 0.8669 - acc: 0.6364 - val_loss: 0.8642 - val_acc: 0.6361\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 207s 114us/step - loss: 0.8412 - acc: 0.6470 - val_loss: 0.8563 - val_acc: 0.6385\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 211s 117us/step - loss: 0.8196 - acc: 0.6564 - val_loss: 0.8545 - val_acc: 0.6398\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 210s 116us/step - loss: 0.7960 - acc: 0.6679 - val_loss: 0.8594 - val_acc: 0.6387\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 3 train Done!\n",
      "2019-08-21 18:13:21\n",
      "3 val_acc: 0.6398159203980099 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "4 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 213s 118us/step - loss: 0.9623 - acc: 0.5978 - val_loss: 0.8874 - val_acc: 0.6281\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 210s 116us/step - loss: 0.8671 - acc: 0.6359 - val_loss: 0.8649 - val_acc: 0.6380\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 211s 117us/step - loss: 0.8413 - acc: 0.6465 - val_loss: 0.8561 - val_acc: 0.6415\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 211s 117us/step - loss: 0.8192 - acc: 0.6565 - val_loss: 0.8530 - val_acc: 0.6418\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 210s 116us/step - loss: 0.7958 - acc: 0.6675 - val_loss: 0.8611 - val_acc: 0.6384\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 4 train Done!\n",
      "2019-08-21 18:31:38\n",
      "4 val_acc: 0.6417711442786069 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "5 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 211s 117us/step - loss: 0.9554 - acc: 0.6000 - val_loss: 0.8841 - val_acc: 0.6298\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 212s 117us/step - loss: 0.8664 - acc: 0.6362 - val_loss: 0.8673 - val_acc: 0.6351\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 213s 118us/step - loss: 0.8406 - acc: 0.6469 - val_loss: 0.8555 - val_acc: 0.6401\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 213s 118us/step - loss: 0.8180 - acc: 0.6571 - val_loss: 0.8571 - val_acc: 0.6398\n",
      "Epoch 00004: early stopping\n",
      "\n",
      " 5 train Done!\n",
      "2019-08-21 18:46:28\n",
      "5 val_acc: 0.6401393034825871 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "6 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 217s 120us/step - loss: 0.9641 - acc: 0.5970 - val_loss: 0.8902 - val_acc: 0.6256\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 215s 119us/step - loss: 0.8681 - acc: 0.6355 - val_loss: 0.8682 - val_acc: 0.6340\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 215s 119us/step - loss: 0.8417 - acc: 0.6467 - val_loss: 0.8575 - val_acc: 0.6395\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 215s 119us/step - loss: 0.8197 - acc: 0.6562 - val_loss: 0.8567 - val_acc: 0.6391\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 216s 119us/step - loss: 0.7969 - acc: 0.6673 - val_loss: 0.8574 - val_acc: 0.6386\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 6 train Done!\n",
      "2019-08-21 19:05:13\n",
      "6 val_acc: 0.6390895522388059 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "7 split Done!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 215s 119us/step - loss: 0.9752 - acc: 0.5937 - val_loss: 0.8879 - val_acc: 0.6269\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 216s 119us/step - loss: 0.8701 - acc: 0.6349 - val_loss: 0.8681 - val_acc: 0.6350\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 217s 120us/step - loss: 0.8444 - acc: 0.6456 - val_loss: 0.8596 - val_acc: 0.6382\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 220s 122us/step - loss: 0.8226 - acc: 0.6553 - val_loss: 0.8544 - val_acc: 0.6400\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 216s 120us/step - loss: 0.8008 - acc: 0.6656 - val_loss: 0.8590 - val_acc: 0.6384\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 7 train Done!\n",
      "2019-08-21 19:24:04\n",
      "7 val_acc: 0.640049751243781 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "8 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 218s 120us/step - loss: 0.9545 - acc: 0.6009 - val_loss: 0.8864 - val_acc: 0.6277\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 215s 119us/step - loss: 0.8647 - acc: 0.6370 - val_loss: 0.8641 - val_acc: 0.6372\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 216s 120us/step - loss: 0.8379 - acc: 0.6483 - val_loss: 0.8563 - val_acc: 0.6398\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 217s 120us/step - loss: 0.8154 - acc: 0.6583 - val_loss: 0.8556 - val_acc: 0.6401\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 218s 121us/step - loss: 0.7901 - acc: 0.6705 - val_loss: 0.8654 - val_acc: 0.6359\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 8 train Done!\n",
      "2019-08-21 19:42:55\n",
      "8 val_acc: 0.6401243781094528 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "9 split Done!\n",
      "\n",
      "Train on 1809000 samples, validate on 201000 samples\n",
      "Epoch 1/100\n",
      "1809000/1809000 [==============================] - 218s 121us/step - loss: 0.9769 - acc: 0.5940 - val_loss: 0.8864 - val_acc: 0.6280\n",
      "Epoch 2/100\n",
      "1809000/1809000 [==============================] - 215s 119us/step - loss: 0.8695 - acc: 0.6352 - val_loss: 0.8633 - val_acc: 0.6368\n",
      "Epoch 3/100\n",
      "1809000/1809000 [==============================] - 215s 119us/step - loss: 0.8444 - acc: 0.6457 - val_loss: 0.8540 - val_acc: 0.6391\n",
      "Epoch 4/100\n",
      "1809000/1809000 [==============================] - 216s 120us/step - loss: 0.8217 - acc: 0.6553 - val_loss: 0.8528 - val_acc: 0.6404\n",
      "Epoch 5/100\n",
      "1809000/1809000 [==============================] - 215s 119us/step - loss: 0.7995 - acc: 0.6664 - val_loss: 0.8541 - val_acc: 0.6391\n",
      "Epoch 00005: early stopping\n",
      "\n",
      " 9 train Done!\n",
      "2019-08-21 20:01:39\n",
      "9 val_acc: 0.6403582089552239 \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "mean val_acc: 0.6397283604156911\n",
      "2019-08-21 20:02:06\n"
     ]
    }
   ],
   "source": [
    "pt.printTime()\n",
    "for train_index, val_index in kfold.split(csr_trainData,label):\n",
    "    K.clear_session()\n",
    "    trainData, trainLabel, valData, valLabel = csr_trainData[train_index,:], label[train_index], csr_trainData[val_index,:] , label[val_index] \n",
    "    trainLabel,valLabel = np_utils.to_categorical(trainLabel,num_classes=7),np_utils.to_categorical(valLabel,num_classes=7)\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print(currK,'split Done!\\n')\n",
    "    \n",
    "    # 全连接模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3000, activation='tanh', input_shape=(csr_trainData.shape[1],)))\n",
    "    model.add(Dense(2000, activation='relu'))\n",
    "    model.add(Dense(1000, activation='sigmoid'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    #损失函数使用交叉熵\n",
    "    adam = Adam(lr=0.0003)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer = adam,\n",
    "                  metrics=['accuracy'])\n",
    "    #模型训练\n",
    "    batch_size = 10240\n",
    "    epochs = 100\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=1, verbose=2)\n",
    "    bestModel = ModelCheckpoint(model_filePath + str(currK) + r'.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    hist = model.fit(trainData, trainLabel,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      shuffle=True,\n",
    "                      validation_data=(valData,valLabel),\n",
    "                      callbacks=[early_stopping,bestModel],\n",
    "                     ) \n",
    "    print('\\n',currK,'train Done!')\n",
    "    pt.printTime()\n",
    "    \n",
    "    K.clear_session()\n",
    "    model = load_model(model_filePath + str(currK) + r'.h5')\n",
    "    probability = model.predict(valData,batch_size=1024)\n",
    "    val_probability[val_index,:] = probability\n",
    "    \n",
    "    score.append(np.max(hist.history['val_acc']))\n",
    "    y_label = label[val_index]\n",
    "    val_label = np.argmax(probability,axis=1) \n",
    "    print(currK,'val_acc:',accuracy_score(val_label,y_label),'\\n\\n')\n",
    "    \n",
    "    currK += 1\n",
    "    K.clear_session()\n",
    "    del trainData, valData, trainLabel,valLabel,model\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------')\n",
    "print('mean val_acc:', np.mean(score))\n",
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6396512437810945"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(val_probability,axis=1) ,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del csr_trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81634"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2010000, 7)\n",
      "          0         1         2         3         4         5         6\n",
      "0  0.000173  0.000918  0.018802  0.098206  0.199636  0.526218  0.156049\n",
      "1  0.000027  0.506544  0.360741  0.056775  0.053092  0.016939  0.005883\n",
      "2  0.000097  0.002695  0.049279  0.454928  0.249025  0.170397  0.073578\n",
      "3  0.000105  0.067980  0.288192  0.455700  0.119740  0.058952  0.009331\n",
      "4  0.000066  0.060741  0.533396  0.257816  0.098826  0.035453  0.013703\n"
     ]
    }
   ],
   "source": [
    "val_probability = pd.DataFrame(val_probability)\n",
    "print(val_probability.shape)\n",
    "print(val_probability.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probability.drop(labels=[0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probability.to_csv(r'../processed/val_probability_13100.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = r'../model/model13100_NN_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_testData = sparse.load_npz(r'../trainTestData/testData13100.npz')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_test = pd.read_csv(r'../data/age_test.csv',header=None,usecols=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 20:25:39\n",
      "502500/502500 [==============================] - 54s 108us/step\n",
      "1\n",
      "502500/502500 [==============================] - 55s 109us/step\n",
      "2\n",
      "502500/502500 [==============================] - 54s 108us/step\n",
      "3\n",
      "502500/502500 [==============================] - 54s 107us/step\n",
      "4\n",
      "295936/502500 [================>.............] - ETA: 23s"
     ]
    }
   ],
   "source": [
    "pt.printTime()\n",
    "proflag = True\n",
    "model_Num = 0\n",
    "for i in list(range(10)):\n",
    "    model = load_model(model_file + str(i) + '.h5')\n",
    "    if proflag==True:\n",
    "        probability = model.predict(csr_testData,batch_size=1024,verbose=1)\n",
    "        proflag = False\n",
    "    else:\n",
    "        probability += model.predict(csr_testData,batch_size=1024,verbose=1)\n",
    "    model_Num += 1\n",
    "    print(model_Num)\n",
    "    K.clear_session()\n",
    "    del model\n",
    "pt.printTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability /= model_Num\n",
    "age = np.argmax(probability,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_test = pd.read_csv(r'../data/age_test.csv',header=None,usecols=[0])\n",
    "age_test = age_test.values\n",
    "type(age_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probability.shape)\n",
    "pro = np.column_stack((age_test,probability))\n",
    "pro = pd.DataFrame(pro)\n",
    "pro.drop(labels=[0,1],axis=1,inplace=True)\n",
    "print(pro.shape)\n",
    "pro.to_csv(r'../processed/test_probability_13100.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
